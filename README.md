[Virtual Reality for Robotics](https://corsi.unige.it/en/off.f/2022/ins/60239?codcla=10635)<br>
**Programmer(s):** [Ankur Kohli](https://github.com/ankurkohli007), [Ammar Iqbal](https://github.com/ammariqbal48), [Basit Akram](https://github.com/abdulbasit656) & [Naveed Manzoor Afridi](https://github.com/Naveed776)<br>
[M.Sc Robotics Engineering](https://corsi.unige.it/corsi/10635)<br>
[University of Genoa (UniGe), Italy](https://unige.it/en)<br>
**Supervisor:** [Prof. Gianni Viardo Vercelli](https://rubrica.unige.it/personale/VUZCWVtr)

# Photogrammetry and 3D Model Reconstruction

## Abstract

This project provides a concise overview of photogrammetry and 3D model reconstruction. Photogrammetry is a technique that uses photographs to extract 3D geometric information, while 3D model reconstruction involves converting raw data into a digital representation. These technologies have diverse applications in fields such as architecture, archaeology, virtual reality, robotics, and manufacturing. Challenges include complex scenes, lighting variations, and algorithm scalability. Integration with other technologies offers further opportunities. Photogrammetry and 3D model reconstruction have the potential to revolutionize industries and enable new possibilities in various fields. RealityCapture is the state-of-the-art photogrammetry software solution that is changing the industry. It is currently the fastest solution on the market, which brings effectivity to your work and allows you to focus on your targets.

## Problem Statement

Photogrammetry and 3D model reconstruction face several challenges that hinder their widespread adoption and optimal performance. These challenges include complex scenes, lighting variations, occlusions, image noise, algorithm scalability, and integration with other technologies. Overcoming these challenges is crucial to improving the accuracy, efficiency, and applicability of photogrammetry and 3D model reconstruction in various industries and fields. Addressing these issues will enable more accurate and detailed 3D models, enhance their usability in real-world scenarios, and open up new possibilities for applications such as architectural design, cultural heritage preservation, virtual reality experiences, robotics, and industrial manufacturing. Therefore, research and development efforts should focus on developing robust algorithms, enhancing data processing techniques, and exploring innovative integration approaches to tackle these challenges and unlock the full potential of photogrammetry and 3D model reconstruction.

In the context of Virtual Reality (VR) for Robotics, the problem lies in the limitations and challenges faced by photogrammetry and 3D model reconstruction techniques when applied to create accurate and detailed 3D models for virtual environments used in robotics applications.

One key challenge is the need for highly precise and real-time 3D models that can be seamlessly integrated with virtual reality environments. The accuracy of the reconstructed models is crucial for tasks such as object recognition, motion planning, and robot manipulation. However, the existing photogrammetry and 3D model reconstruction techniques may not always provide the required level of accuracy and real-time performance necessary for robotics in VR.

Another challenge is the ability to handle complex scenes and dynamic environments. Robotics applications often involve objects or scenes with complex geometries, occlusions, and changing lighting conditions. Photogrammetry and 3D model reconstruction algorithms need to effectively handle these challenges and provide reliable and up-to-date 3D models that accurately represent the environment.

Moreover, the scalability of the reconstruction process is critical. Robotics applications often require real-time updates of the 3D models to accommodate dynamic changes in the environment. The ability to efficiently process large datasets and update the 3D models in real-time is crucial for providing an immersive and interactive experience in VR for robotics.

Additionally, the integration of photogrammetry and 3D model reconstruction with other technologies used in robotics, such as sensor fusion or real-time tracking systems, is essential. Seamless integration can enhance the accuracy and reliability of the virtual environment, enabling better interaction and decision-making for robotic systems.

Addressing these challenges in photogrammetry and 3D model reconstruction for VR in robotics is crucial for creating immersive and realistic virtual environments that can accurately simulate real-world scenarios. By developing improved algorithms, handling complex scenes and dynamic environments, ensuring scalability, and integrating with other technologies, photogrammetry and 3D model reconstruction can enhance the capabilities of VR in robotics and enable more sophisticated and efficient robotic applications in virtual environments.

## Problem Solution

To address the challenges in photogrammetry and 3D model reconstruction for virtual reality (VR) in robotics, the utilization of Reality Capture technology offers a promising solution. Reality Capture combines photogrammetry, laser scanning, and structured light scanning techniques to create highly accurate and detailed 3D models of real-world objects and scenes.

By employing Reality Capture, real-time reconstruction of 3D models can be achieved, providing up-to-date and precise representations of the environment for VR robotics applications. The advanced algorithms and processing capabilities of Reality Capture enable efficient and accurate reconstruction, ensuring the virtual environment accurately mirrors the real world.

One advantage of Reality Capture is its ability to handle complex scenes and dynamic environments. With its integration of multiple scanning technologies, it can effectively capture and reconstruct objects with intricate geometries, occlusions, and changing lighting conditions. This capability enhances the accuracy and realism of the virtual environment for robotics tasks, enabling more reliable object recognition, motion planning, and robot manipulation.

Furthermore, Reality Capture offers scalable processing capabilities to handle large datasets and enable real-time updates of 3D models. The parallel processing and distributed computing capabilities of the technology ensure efficient data processing, allowing for seamless integration with VR robotics applications. Real-time updates of the 3D models facilitate an immersive and interactive experience, enabling robots to interact with the virtual environment in real-time and respond to dynamic changes.

The integration of Reality Capture with other technologies used in robotics, such as sensor fusion and tracking systems, further enhances the capabilities of VR robotics. By fusing data from different sensors and incorporating real-time tracking information, the accuracy and reliability of the virtual environment are significantly improved, enabling precise localization, object tracking, and interaction between the virtual objects and the robotic system.

Overall, the utilization of Reality Capture technology provides an effective solution to the challenges faced in photogrammetry and 3D model reconstruction for VR in robotics. With its real-time reconstruction capabilities, handling of complex scenes, scalability, and integration with other technologies, Reality Capture enhances the accuracy, realism, and usability of the virtual environment for robotics applications, opening up new possibilities for advanced and efficient robotic tasks in virtual reality settings.

## Introduction

Photogrammetry is a technique of using photographs to generate 3D models or maps of objects and landscapes. This technique involves capturing multiple images of an object or a scene from different angles and using software to combine them into a 3D model. The resulting 3D model can be used for a variety of applications, including virtual reality, robotics, and more.

One of the most exciting applications of photogrammetry is in virtual reality for robotics. By using photogrammetry to create 3D models of real-world objects and environments, it is possible to create immersive virtual reality simulations that can be used to train and test robots. This technology can be used to train robots to perform tasks in a safe and controlled environment, without the risk of damaging real-world equipment or injuring people.

Additionally, photogrammetry can be used to create 3D models of existing equipment or environments, which can be used to design and test new robotics systems. For example, if a company is designing a new robot to operate in a factory environment, they can use photogrammetry to create a 3D model of the factory, which can be used to simulate the robot's movements and test its effectiveness before it is actually built and deployed.

Overall, photogrammetry and 3D model reconstruction have a lot of potential for virtual reality and robotics applications. As the technology continues to improve, we can expect to see more and more innovative uses for these techniques in the field of robotics.

<p align="center">
  <img width="700" height="600" src="https://github.com/ankurkohli007/Photogrammetry-and-3D-Model-Reconstruction_Virtual-Reality-for-Robotics/blob/18271856fb9a75cddfa5aba2fc39f3c2780c6ded/How%20to%20turn%203D%20images%20into%203D%20Assets%20with%20a%20simple%20workflow.png">
</p>

<p align="center">
    <em>How to turn 3D images into 3D Assets with a simple workflow</em>
</p>

*Note:* Source of above picture is from [The Ultimate Guide to 3D Reconstruction with Photogrammetry](https://towardsdatascience.com/the-ultimate-guide-to-3d-reconstruction-with-photogrammetry-56155516ddc4)

**3D Data Acquisition:** 3D data acquisition refers to the process of capturing information about the threedimensional shape, surface, and/or appearance of an object or scene using specialized equipment or techniques. This can be done using a variety of methods, such as structured light, laser scanning, photogrammetry, and computer vision, among others. The captured data can then be used for a variety of purposes, such as computer graphics, scientific visualization, measurement, and inspection.

**3D Data Processing:** 3D data processing refers to the process of using computer software to analyze and manipulate 3D data captured by a reality capture device, such as a laser scanner or photogrammetry camera. This can include tasks such as cleaning and filtering the data, aligning and merging multiple scans or images, and creating a 3D model or point cloud of the captured environment. The resulting 3D data can be used for a variety of purposes, including building and construction, asset management, heritage preservation, and more.

## State of Art

Photogrammetry is a technique for creating three-dimensional models and maps from two-dimensional images. It involves taking a series of photographs from different angles and using specialized software such as Capture Reality and Unreal Engine to process the images and generate a 3D model or map.

One of the key challenges in photogrammetry is accurately aligning the images, which is known as image registration. This can be difficult due to factors such as variations in lighting, camera position, and image distortion. To address these challenges, researchers have developed techniques such as feature-based alignment
and structure-from-motion.

Another important aspect of photogrammetry is the creation of accurate and detailed 3D models. This can be achieved through the use of techniques such as multi-view stereo, which involves comparing multiple images of the same scene to generate a 3D point cloud. Other techniques, such as lidar and structured light, can also be
used to create high-resolution 3D models.

Recent advances in machine learning have also led to the development of neural network-based methods for photogrammetry. These methods can learn to align images and create 3D models from large datasets, and have the potential to significantly improve the accuracy and speed of photogrammetry.

Overall, photogrammetry and 3D model reconstruction are active areas of research with numerous practical applications, including mapping, architectural documentation, and heritage preservation.

Also, the state of the art in photogrammetry and 3D model reconstruction in terms of virtual reality (VR) for robotics has seen significant progress. Here are some key advancements in the field:

Real-Time Reconstruction: Real-time reconstruction techniques have been developed to generate 3D models in real-time or near real-time, enabling immediate integration with VR environments for robotics. These techniques leverage parallel processing, efficient algorithms, and optimized data structures to achieve fast reconstruction speeds, facilitating real-time interactions between robots and the virtual environment.

Sensor Fusion and Calibration: Integration of photogrammetry with other sensors, such as depth sensors or inertial measurement units (IMUs), allows for sensor fusion and calibration. This integration improves the accuracy of 3D reconstructions by combining visual data with depth or motion information, enabling more precise localization and object tracking in VR for robotics.

Dynamic Scene Handling: Advanced algorithms have been developed to handle dynamic scenes in VR for robotics. These algorithms can detect and track moving objects, handle changing lighting conditions, and accurately update the 3D models in real-time. This capability is essential for maintaining the accuracy and realism of the virtual environment and ensuring seamless interactions between robots and dynamic virtual objects.

Multi-Modal Data Integration: Integration of multiple data modalities, such as RGB images, depth maps, and point cloud data, enhances the fidelity of 3D model reconstructions. By combining data from different sensors, algorithms can leverage the strengths of each modality to improve accuracy, handle occlusions, and capture fine details in the virtual environment for robotics.

Interactive User Interfaces: User interfaces and tools have been developed to facilitate user interaction and manipulation within the VR environment for robotics. These interfaces allow users to directly interact with virtual objects, perform object manipulation tasks, and provide haptic feedback, enhancing the immersive experience and enabling intuitive control of robotic systems in VR scenarios.

Deep Learning and AI Techniques: Deep learning and AI techniques have been applied to various aspects of photogrammetry and 3D model reconstruction in VR for robotics. Convolutional neural networks (CNNs) and generative models have been utilized for feature extraction, object recognition, and scene understanding, improving the efficiency and accuracy of reconstruction algorithms.

Cloud-Based Solutions: Cloud-based photogrammetry services have emerged, offering scalable and on-demand computational resources for 3D model reconstruction in VR for robotics. These services allow users to upload their data to the cloud, where the reconstruction process is performed, enabling faster processing, large-scale reconstructions, and accessibility for users with limited computational resources.

It's important to note that the field of photogrammetry and 3D model reconstruction in VR for robotics is rapidly evolving. Ongoing research continues to push the boundaries of accuracy, real-time performance, and integration capabilities, with the aim of providing more realistic and interactive VR environments for robotics applications.

## Tools Used

There are enormous tools used to accomplish the task such as Reality Capture, and Unreal Engine.

### **Reality Capture:** [Reality Capture](https://www.capturingreality.com/realitycapture) is a leading software tool used in the field of photogrammetry and 3D model reconstruction. It offers advanced capabilities for capturing and processing images to create highly detailed and accurate 3D models of real-world objects and scenes. Here are some key features and functionalities of Reality Capture:

1. **Image-based Reconstruction:** Reality Capture uses a collection of images taken from different viewpoints to reconstruct 3D models. It employs advanced algorithms to align and stitch these images together, extracting geometric and textural information to create a 3D representation of the scene.

2. **Multiple Input Sources:** The software supports various input sources, including standard RGB images, laser scans, and structured light scans. It can seamlessly integrate data from different sources to create a comprehensive and detailed 3D model.

3. **Automatic Alignment and Calibration:** Reality Capture automates the alignment and calibration process, making it easier to handle large datasets. The software identifies common features in the images and automatically aligns them to create an accurate representation of the scene.

4. **Dense Point Cloud Generation:** By leveraging multi-view stereo algorithms, Reality Capture generates dense point clouds, capturing intricate details and providing a solid foundation for the 3D model reconstruction process.

5. **High-Quality Texturing:** The software enables high-quality texturing of the reconstructed 3D models by applying the original images' textures onto the model's surface. This results in realistic and visually appealing representations of the captured scene.

6. **Mesh Generation and Optimization:** Reality Capture generates optimized meshes from the dense point clouds, producing a continuous and watertight 3D surface. The software employs various optimization techniques to refine the mesh and enhance its visual quality.

7. **Export and Integration:** The 3D models created in Reality Capture can be exported in various file formats, including industry-standard formats such as OBJ, FBX, and PLY. This allows for seamless integration with other software tools and platforms used in 3D visualization, virtual reality, and robotics.

8. **Scalability and Performance:** Reality Capture is designed to handle large-scale datasets efficiently. It leverages advanced processing techniques and can utilize multiple computing resources, such as GPUs, to accelerate the reconstruction process and achieve high-performance results.

9. **User-Friendly Interface:** The software provides an intuitive and user-friendly interface, making it accessible to both experts and beginners. It offers a range of automated tools and guided workflows that streamline the reconstruction process and make it easier to achieve high-quality results.

Overall, Reality Capture is a powerful and versatile tool for photogrammetry and 3D model reconstruction. Its advanced capabilities, automation features, and scalability make it a popular choice among professionals in industries such as architecture, archaeology, gaming, visual effects, and robotics.

### **Unreal Engine:** Unreal Engine is a popular and powerful real-time 3D engine and development platform created by Epic Games. It provides a comprehensive suite of tools and features for creating interactive and immersive experiences across various platforms, including video games, virtual reality (VR), augmented reality (AR), architectural visualization, and more. Here are some key aspects and features of Unreal Engine:

1. **Real-time Rendering:** Unreal Engine offers advanced real-time rendering capabilities, allowing developers to create stunning and realistic visuals. It supports high-quality materials, lighting, shadows, and post-processing effects to achieve lifelike graphics.

2. **Blueprints Visual Scripting:** Unreal Engine includes a visual scripting system called Blueprints, which enables non-programmers to create gameplay mechanics, interactive elements, and complex behaviors using a node-based interface. It provides a user-friendly way to create game logic without writing code.

3. **Content Creation Tools:** The engine provides a range of powerful tools for content creation, including a robust editor for designing levels and environments, a material editor for creating and editing materials, a particle system for visual effects, and a physics engine for realistic simulations.

4. **Cross-platform Development:** Unreal Engine supports cross-platform development, allowing developers to create applications for PC, consoles, mobile devices, VR headsets, and AR platforms. It provides built-in support for major platforms, simplifying the process of deploying projects to different devices.

5. **Blueprint Visual Scripting:** Unreal Engine includes a visual scripting system called Blueprints, which enables non-programmers to create gameplay mechanics, interactive elements, and complex behaviors using a node-based interface. It provides a user-friendly way to create game logic without writing code.

6. **Marketplace and Community:** Unreal Engine has a thriving marketplace where developers can access a wide range of assets, including 3D models, materials, animations, and plugins, to enhance their projects. The engine also has a strong community of developers who actively share knowledge, provide support, and contribute to the growth of the engine.

7. **Performance and Optimization:** Unreal Engine offers various optimization features and techniques to ensure high-performance execution. This includes tools for profiling and debugging, GPU and CPU optimization, and efficient memory management.

8. **Blueprint Visual Scripting:** Unreal Engine includes a visual scripting system called Blueprints, which enables non-programmers to create gameplay mechanics, interactive elements, and complex behaviors using a node-based interface. It provides a user-friendly way to create game logic without writing code.

9. **Industry Adoption:** Unreal Engine is widely adopted in the gaming industry and beyond. It has been used to develop highly acclaimed games, VR experiences, animated films, architectural visualizations, and training simulations. Its versatility and feature set make it a popular choice for a wide range of projects.

Unreal Engine continues to evolve and introduce new features with regular updates, empowering developers to create cutting-edge and immersive experiences across multiple industries.

## Description 

The project of Photogrammetry and 3D Model Reconstruction in terms of Virtual Reality for Robotics aims to leverage the power of photogrammetry and 3D model reconstruction techniques in the context of virtual reality (VR) to enhance robotics applications. The project involves capturing images of the real-world environment using cameras or other imaging devices and using photogrammetry algorithms to reconstruct a detailed and accurate 3D model of the scene.

The 3D model, along with the captured images, is then integrated into a virtual reality environment, creating a realistic and immersive virtual representation of the physical space. This virtual environment serves as a simulation platform where robotic systems can be tested, trained, and interacted with.

The project focuses on developing advanced techniques to handle the challenges specific to robotics applications, such as real-time reconstruction, dynamic scene handling, and accurate object tracking. It explores the integration of multiple sensors, such as RGB cameras, depth sensors, and inertial measurement units (IMUs), to improve the accuracy and reliability of the 3D reconstructions.

In addition, the project aims to develop interactive user interfaces and control mechanisms within the virtual reality environment, enabling users to manipulate virtual objects, control robotic systems, and receive haptic feedback. The integration of robotics frameworks, such as robot simulators or control systems, with the virtual environment is also a key aspect of the project.

The ultimate goal of the project is to create a seamless integration between the physical and virtual worlds, allowing robotic systems to perceive and interact with the virtual environment in a realistic and intuitive manner. This integration opens up possibilities for various robotics applications, including robot training, task planning, autonomous navigation, and human-robot interaction.

Through this project, the potential of photogrammetry and 3D model reconstruction in the context of virtual reality is harnessed to advance the field of robotics and pave the way for more sophisticated and immersive robotic applications in diverse industries.

## Reference Links ###

1. Learn about https://www.capturingreality.com/realitycapture with tutorials in https://dev.epicgames.com/community/learning?application=capturing_reality  and News
2. Check also the community https://dev.epicgames.com/community/?application=capturing_reality
3. Also the News https://www.capturingreality.com/News
4. Follow this report from Medium.com https://towardsdatascience.com/the-ultimate-guide-to-3d-reconstruction-with-photogrammetry-56155516ddc4
5. Unreal Engine | The most powerful real-time 3D creation tool — unrealengine.com. https://www.unrealengine.com/en-US.
6. Ph.D. Florent Poux. The Ultimate Guide to 3D Reconstruction with Pho- togrammetry — towardsdatascience.com. https://towardsdatascience.com/ the-ultimate-guide-to-3d-reconstruction-with-photogrammetry-56155516ddc4. [Accessed 08- Jan-2023].
7. David Novotny Georgia Gkioxari, Shubham Tulsiani. Pushing state-of-the-art in 3D content understanding — ai.facebook.com. https://ai.facebook.com/blog/ pushing-state-of-the-art-in-3d-content-understanding/, February 18, 2019.
8. https://github.com/luigifreda/ROSIntegration
9. file:///Users/ankurkohli007/Downloads/6.2020-1343.pdf
10. https://par.nsf.gov/servlets/purl/10297241
11. https://www.youtube.com/watch?v=zDUaazmSukM
12. https://www.youtube.com/watch?v=fuB4OWxOhME
13. https://www.youtube.com/watch?v=pcI08fHL9Nw
14. https://dev.epicgames.com/community/learning/courses/x6D/capturing-reality-drone-mapping-guide/3Y1J/capturing-reality-drone-mapping-guide-introduction
15. https://docs.unrealengine.com/4.27/en-US/ProgrammingAndScripting/Blueprints/BP_HowTo/WorkingWithMaps/
16. https://www.unrealengine.com/marketplace/en-US/product/3d-map-navigation-in-vr-course
17. https://embeddedcomputing.com/application/industrial/automation-robotics/drone-photogrammetry-how-can-you-turn-drone-images-into-3d-mapsmodels
18. https://forums.unrealengine.com/t/how-to-make-a-3d-map-menu/501819
19. https://www.youtube.com/watch?v=9lGupuc90oM
20. https://www.youtube.com/watch?v=dmxrN7uUUhs
21. https://github.com/Unity-Technologies/Robotics-Nav2-SLAM-Example
22. https://resources.unity.com/automotive-transportation-manufacturing-content/unity-robotics-slam
23. https://www.luigifreda.com/2019/09/22/rosintegration-for-ue-4-23/
24. https://www.youtube.com/watch?v=n6RjVbh3Vgc
25. https://www.kaggle.com/datasets/birdy654/environment-recognition-simulation-to-reality
26. https://github.com/jordan-bird/Unity-Image-Dataset-Collector
27. https://www.youtube.com/watch?v=CJG0U1VLp-s
28. https://www.youtube.com/watch?v=y-77QBAy73E
29. https://www.youtube.com/watch?v=XxQsIYUFGrQ
30. https://educatorsinvr.com/2020/12/09/photogrammetry-examples-and-resources/
31. https://educatorsinvr.com/2020/12/09/photogrammetry-examples-and-resources/
32. https://www.researchgate.net/publication/327227913_PHOTOGRAMMETRIC_3D_MODELING_FOR_VIRTUAL_REALITY#fullTextFileContent

<br>
<br>
https://www.skyebrowse.com/

<br>
<br>
https://www.youtube.com/watch?v=WrCOhes1Zgg&feature=youtu.be&themeRefresh=1
<br>
<br>
capturingreality.com/architecture<br>
https://www.capturingreality.com/Showcase<br>
https://www.capturingreality.com/interior-re-desing-with-realitycapture<br>
https://overhead4d.com/index.html<br>
<br>
<br>
<br>
<br>

